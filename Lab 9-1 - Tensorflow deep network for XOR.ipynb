{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with logistic refression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.loadtxt.html\n",
    "xy = np.loadtxt('train_data/lab9-1_train.txt', unpack=True)\n",
    "x_data = np.transpose(xy[0:-1])\n",
    "y_data = np.reshape(xy[-1], (4,1))\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, len(x_data)], -1.0, 1.0))\n",
    "\n",
    "# Our hypothesis\n",
    "h = tf.matmul(W, X)\n",
    "hypothesis = tf.div(1., 1.+tf.exp(-h))\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1.-hypothesis))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.01) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Before starting, initialize the bariables. We will 'run' this first.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.695131 [[-0.54783797 -0.7434423  -0.99530113  0.87447751]]\n",
      "200 0.69435 [[-0.54783797 -0.77218461 -0.96835333  0.87268329]]\n",
      "400 0.693877 [[-0.54783797 -0.79430526 -0.94708174  0.87183428]]\n",
      "600 0.693589 [[-0.54783797 -0.81140679 -0.93038201  0.87143278]]\n",
      "800 0.693415 [[-0.54783797 -0.82466477 -0.91731369  0.87124342]]\n",
      "[array([[ 0.49100143,  0.50905883]], dtype=float32), array([[ 0.,  1.]], dtype=float32), array([[ True, False],\n",
      "       [False,  True],\n",
      "       [False,  True],\n",
      "       [ True, False]], dtype=bool), 0.5]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # fit the line.\n",
    "    for step in range(1000):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis + 0.5), Y)\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does not work!\n",
    "우리가 예상한 값은 [0,1,1,0]이지만 결과는 [1,1,0,0]이 나옴  \n",
    "50% 밖에 맞지 않음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_uniform([2,2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([2,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Our hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.1) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Before starting, initialize the bariables. We will 'run' this first.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.720215 [[ 0.87414038 -0.51383328]\n",
      " [ 0.6796999   0.63277024]] [[ 0.60214341]\n",
      " [ 0.18827695]]\n",
      "4000 0.387929 [[ 4.90775537  0.61399132]\n",
      " [ 5.60549736  2.41313958]] [[ 5.5677042]\n",
      " [-3.6628325]]\n",
      "8000 0.0278565 [[ 6.38019085  4.09327745]\n",
      " [ 6.64880466  4.12744379]] [[ 8.84407139]\n",
      " [-9.50091362]]\n",
      "12000 0.0131026 [[ 6.77163839  4.6391139 ]\n",
      " [ 6.958076    4.66630936]] [[ 10.12051582]\n",
      " [-10.91417217]]\n",
      "16000 0.00849369 [[ 6.99005032  4.92252922]\n",
      " [ 7.14098024  4.94578981]] [[ 10.88570213]\n",
      " [-11.71309376]]\n",
      "20000 0.00626431 [[ 7.13969326  5.11047363]\n",
      " [ 7.2699542   5.13115549]] [[ 11.43267536]\n",
      " [-12.27146339]]\n",
      "[array([[ 0.00766805],\n",
      "       [ 0.99439323],\n",
      "       [ 0.99432111],\n",
      "       [ 0.00602377]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # fit the line.\n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 4000 == 0:\n",
    "            print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W1), sess.run(W2))\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy],\n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wide network: Use more neurons in each layer. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.696199 [[-0.60511547 -0.30814201  0.72101784 -0.44072786 -0.52743822 -0.52494985\n",
      "   0.82023078 -0.47523519  0.45831645  0.44436476]\n",
      " [ 0.56247801  0.44132757  0.75539881 -0.34457281 -0.01685247 -0.72980714\n",
      "  -0.93928814  0.99081457  0.62967372 -0.59601557]] [[ 0.19279987]\n",
      " [ 0.30260223]\n",
      " [ 0.50413382]\n",
      " [-0.8679266 ]\n",
      " [-0.86838031]\n",
      " [-0.94578373]\n",
      " [ 0.0179239 ]\n",
      " [ 0.29100806]\n",
      " [ 0.16387145]\n",
      " [ 0.39473936]]\n",
      "4000 0.0748434 [[-3.98894525 -2.04667044  3.19953847  0.86206311  1.11588979 -4.96113443\n",
      "   0.95689529 -0.25528294  1.10183704  1.88897526]\n",
      " [ 2.22388458  0.3829039   3.26879835  0.5600692   1.32530522 -5.0237813\n",
      "  -2.44750023  1.60399044  1.04467309 -3.64847136]] [[ 4.21929455]\n",
      " [ 1.94129074]\n",
      " [ 3.00831676]\n",
      " [-1.49375117]\n",
      " [-2.83520269]\n",
      " [-6.59566641]\n",
      " [ 1.92231452]\n",
      " [-1.26308572]\n",
      " [-2.24695611]\n",
      " [ 3.63915038]]\n",
      "8000 0.0126279 [[-4.93072414 -2.63586497  3.67633724  1.06216931  1.71939552 -5.56724644\n",
      "   1.49972129 -0.41105032  1.4885267   2.85678005]\n",
      " [ 3.27815628  0.78718275  3.73652601  0.6675607   1.77672279 -5.6206584\n",
      "  -3.10460758  1.98130155  1.38769269 -4.54558945]] [[ 5.94309664]\n",
      " [ 2.50092459]\n",
      " [ 3.68056822]\n",
      " [-1.98086047]\n",
      " [-3.84318352]\n",
      " [-8.02504539]\n",
      " [ 2.72494841]\n",
      " [-1.83112836]\n",
      " [-3.06880474]\n",
      " [ 5.10322809]]\n",
      "12000 0.00607991 [[-5.20476198 -2.8454349   3.83337593  1.12856233  1.95748484 -5.7458868\n",
      "   1.71593344 -0.50123918  1.64985847  3.17302942]\n",
      " [ 3.61274028  0.97135568  3.89442563  0.69795066  1.96392417 -5.80074883\n",
      "  -3.32801437  2.12082863  1.53184378 -4.8100667 ]] [[ 6.54384947]\n",
      " [ 2.71513891]\n",
      " [ 3.92275071]\n",
      " [-2.14462805]\n",
      " [-4.23793983]\n",
      " [-8.5039587 ]\n",
      " [ 3.0206964 ]\n",
      " [-2.02752948]\n",
      " [-3.37796783]\n",
      " [ 5.61338234]]\n",
      "16000 0.00386477 [[-5.35517979 -2.9685142   3.92376351  1.16778421  2.10025096 -5.84496927\n",
      "   1.84733105 -0.5627017   1.75049388  3.35152864]\n",
      " [ 3.80024242  1.08943558  3.98626876  0.71545786  2.07916474 -5.90161276\n",
      "  -3.45624352  2.20495558  1.62181973 -4.95523214]] [[ 6.89499807]\n",
      " [ 2.84847736]\n",
      " [ 4.06831932]\n",
      " [-2.239254  ]\n",
      " [-4.47934437]\n",
      " [-8.78274822]\n",
      " [ 3.19834781]\n",
      " [-2.14318895]\n",
      " [-3.56562996]\n",
      " [ 5.91028214]]\n",
      "20000 0.00278747 [[-5.45616674 -3.05437851  3.98621559  1.19543016  2.20071864 -5.91196203\n",
      "   1.94075012 -0.60944414  1.82320535  3.4730041 ]\n",
      " [ 3.92742777  1.1761111   4.05013037  0.72781134  2.16157126 -5.97022915\n",
      "  -3.54441237  2.264745    1.68688858 -5.05260992]] [[ 7.13964987]\n",
      " [ 2.94547105]\n",
      " [ 4.17174339]\n",
      " [-2.30475736]\n",
      " [-4.65203047]\n",
      " [-8.97685719]\n",
      " [ 3.32426977]\n",
      " [-2.22444677]\n",
      " [-3.69959831]\n",
      " [ 6.11637545]]\n",
      "[array([[ 0.00199151],\n",
      "       [ 0.99718791],\n",
      "       [ 0.99740809],\n",
      "       [ 0.00373805]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 4000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0))\n",
    "\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.771545 [[-0.52903324  0.69870329 -0.03112978 -0.84536332  0.0306104 ]\n",
      " [ 0.49851146 -0.55360097 -0.25324705 -0.96951008 -0.05127549]] [[-0.49905097  0.21191521  0.94059336 -0.18701103]\n",
      " [ 0.02787192 -0.63945204  0.89419991 -0.99158889]\n",
      " [-0.51910573 -0.83378035 -0.31925189 -0.69106519]\n",
      " [ 0.84683406 -0.43074334  0.28659174 -0.61934024]\n",
      " [-0.22357935  0.66982335  0.64668    -0.21907875]]\n",
      "4000 0.565237 [[-0.46245572  2.25516248  0.12671506 -2.91392279  0.10296836]\n",
      " [ 0.54753196 -1.09154069 -0.42812011 -2.78314757 -0.05475603]] [[-0.37615064  0.16874325  0.73164707  0.26765952]\n",
      " [ 0.23662229 -0.53476053  0.90925115 -1.46448863]\n",
      " [-0.61298555 -0.88003689 -0.68644118 -0.14716712]\n",
      " [ 1.8068856   0.01620655  1.29206204 -2.12067866]\n",
      " [-0.25306392  0.63263464  0.34413883  0.20570481]]\n",
      "8000 0.00895151 [[-0.24447788  5.1082058   1.11432636 -5.06388283 -0.15630572]\n",
      " [ 1.15111411 -3.27306223 -3.96538782 -4.79304743 -1.33744121]] [[-0.15568954  0.19045594  0.74721485 -0.35238701]\n",
      " [ 2.2063961  -0.45134178  2.70243621 -3.84896541]\n",
      " [-2.45319676 -0.92901111 -2.69850039  3.19657135]\n",
      " [ 3.20106816  0.08063832  2.90547299 -4.06395531]\n",
      " [-1.0494988   0.61962283 -0.6048246   1.5749954 ]]\n",
      "12000 0.00321806 [[-0.22573836  5.37603569  1.38057983 -5.1963439  -0.22371857]\n",
      " [ 1.19273865 -3.53521538 -4.28637838 -4.97380257 -1.43319106]] [[-0.18233617  0.19012055  0.70786393 -0.3635529 ]\n",
      " [ 2.51808381 -0.45659479  3.00852513 -4.1791563 ]\n",
      " [-2.6792953  -0.92683381 -2.92205906  3.52435327]\n",
      " [ 3.33494186  0.07811613  3.08021879 -4.25203371]\n",
      " [-1.17927802  0.62053788 -0.72974443  1.73866129]]\n",
      "16000 0.00188893 [[-0.21736534  5.50090933  1.51650333 -5.25724363 -0.26621413]\n",
      " [ 1.21145535 -3.65509725 -4.43598509 -5.05534267 -1.47762084]] [[-0.19350703  0.18986531  0.69135857 -0.36916593]\n",
      " [ 2.67217588 -0.46055922  3.15883756 -4.3366313 ]\n",
      " [-2.7947998  -0.92506462 -3.03700328  3.68093395]\n",
      " [ 3.39733243  0.07625484  3.1605835  -4.3361001 ]\n",
      " [-1.24650323  0.62125313 -0.79420114  1.81816196]]\n",
      "20000 0.0013188 [[-0.21212536  5.58037853  1.60666466 -5.29572725 -0.29757521]\n",
      " [ 1.22324896 -3.73063779 -4.53106117 -5.10629272 -1.50581884]] [[-0.19994195  0.18967445  0.68170309 -0.37309054]\n",
      " [ 2.77333283 -0.46364918  3.25717568 -4.43801928]\n",
      " [-2.87210345 -0.92361408 -3.11411309  3.78198433]\n",
      " [ 3.43716764  0.07481718  3.21144199 -4.38844728]\n",
      " [-1.29191852  0.62185824 -0.83766967  1.87004185]]\n",
      "[array([[  6.91048044e-04],\n",
      "       [  9.98561323e-01],\n",
      "       [  9.98692334e-01],\n",
      "       [  1.83394738e-03]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 4000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
