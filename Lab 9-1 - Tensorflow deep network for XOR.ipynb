{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with logistic refression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.loadtxt.html\n",
    "xy = np.loadtxt('train_data/lab9-1_train.txt', unpack=True)\n",
    "x_data = np.transpose(xy[0:-1])\n",
    "y_data = np.reshape(xy[-1], (4,1))\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, len(x_data)], -1.0, 1.0))\n",
    "\n",
    "# Our hypothesis\n",
    "h = tf.matmul(W, X)\n",
    "hypothesis = tf.div(1., 1.+tf.exp(-h))\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.01) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Before starting, initialize the bariables. We will 'run' this first.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.823534 [[ 0.81494784 -0.79384154 -0.04151426 -0.56615359]]\n",
      "200 0.73328 [[ 0.81494784 -0.55438042  0.04998901 -0.23518892]]\n",
      "400 0.706952 [[ 0.81494784 -0.40540081  0.06945921 -0.06673881]]\n",
      "600 0.698986 [[ 0.81494784 -0.31239125  0.0583694   0.01518091]]\n",
      "800 0.696104 [[ 0.81494784 -0.2519058   0.03707727  0.05437431]]\n",
      "[array([[ 0.52186334,  0.46558082]], dtype=float32), array([[ 1.,  0.]], dtype=float32), array([[False,  True],\n",
      "       [ True, False],\n",
      "       [ True, False],\n",
      "       [False,  True]], dtype=bool), 0.5]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # fit the line.\n",
    "    for step in range(1000):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis + 0.5), Y)\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does not work!\n",
    "우리가 예상한 값은 [0,1,1,0]이지만 결과는 [1,1,0,0]이 나옴  \n",
    "50% 밖에 맞지 않음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_uniform([2, 2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([2, 1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2= tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Our hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.1) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Before starting, initialize the bariables. We will 'run' this first.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.708173 [[-0.47884896  0.49346587]\n",
      " [-0.29835552  0.97950274]] [[ 0.05120474]\n",
      " [ 0.53656435]]\n",
      "4000 0.497867 [[ 0.43444797  4.90236998]\n",
      " [ 0.5924719   4.9158783 ]] [[-0.89916104]\n",
      " [ 4.31880331]]\n",
      "8000 0.0363758 [[ 3.96563601  6.43276787]\n",
      " [ 3.96702051  6.44514942]] [[-8.84007454]\n",
      " [ 8.4118042 ]]\n",
      "12000 0.0148474 [[ 4.62015343  6.83183098]\n",
      " [ 4.62128401  6.84000921]] [[-10.59400558]\n",
      " [  9.88728523]]\n",
      "16000 0.00922296 [[ 4.92886782  7.04842663]\n",
      " [ 4.92984056  7.05493832]] [[-11.49384403]\n",
      " [ 10.72148323]]\n",
      "20000 0.00666375 [[ 5.12687349  7.1954608 ]\n",
      " [ 5.12774086  7.2010417 ]] [[-12.10095406]\n",
      " [ 11.30376244]]\n",
      "[array([[ 0.00807264],\n",
      "       [ 0.99398851],\n",
      "       [ 0.99398524],\n",
      "       [ 0.00646607]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # fit the line.\n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 4000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W1), sess.run(W2))\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis + 0.5), Y)\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wide network: Use more neurons in each layer. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.724131 [[ -9.77419913e-01  -4.46508974e-01   8.91232014e-01   4.72538054e-01\n",
      "    3.15681100e-04  -3.55590641e-01   2.64485270e-01  -7.65561163e-01\n",
      "    5.91937125e-01  -6.36958122e-01]\n",
      " [ -9.41289127e-01  -9.77757931e-01   5.13038278e-01   6.21540427e-01\n",
      "   -6.01109229e-02  -9.54740644e-02  -9.09503758e-01   8.76764297e-01\n",
      "    4.35540587e-01  -6.08670294e-01]] [[ 0.77826536]\n",
      " [ 0.0264528 ]\n",
      " [-0.57920176]\n",
      " [-0.73537982]\n",
      " [ 0.4157536 ]\n",
      " [ 0.53630739]\n",
      " [ 0.74713212]\n",
      " [ 0.76174855]\n",
      " [-0.89140159]\n",
      " [ 0.12504567]]\n",
      "4000 0.0475369 [[-0.67901284 -3.75251913  0.91760194  0.41951516 -0.18584128 -0.56711423\n",
      "   3.88454723 -5.20162582  0.71657544 -2.03415203]\n",
      " [-0.69072241 -3.75404263  0.39696571  0.96043807 -0.34797281 -0.349581\n",
      "  -5.17144775  3.9824934   0.69583714 -1.99820197]] [[ 0.41964954]\n",
      " [-4.36814499]\n",
      " [-1.07985377]\n",
      " [-1.46920991]\n",
      " [ 0.3952693 ]\n",
      " [ 0.66347247]\n",
      " [ 6.51861477]\n",
      " [ 6.55287504]\n",
      " [-1.59711707]\n",
      " [-1.6419307 ]]\n",
      "8000 0.0139586 [[-0.71343887 -4.25359392  1.07601202  0.51918066 -0.27556807 -0.68120158\n",
      "   4.61744356 -6.0275836   0.8805607  -2.2721889 ]\n",
      " [-0.72699767 -4.2532444   0.47571647  1.16311502 -0.44554913 -0.44376007\n",
      "  -5.99889231  4.69340229  0.86035633 -2.24346113]] [[ 0.61829191]\n",
      " [-5.17717743]\n",
      " [-1.50074339]\n",
      " [-1.91470003]\n",
      " [ 0.46559745]\n",
      " [ 0.80884004]\n",
      " [ 8.38515759]\n",
      " [ 8.42648888]\n",
      " [-2.05312037]\n",
      " [-1.89448345]]\n",
      "12000 0.00785279 [[-0.73291558 -4.46499538  1.15334964  0.56737876 -0.31418091 -0.7296831\n",
      "   4.91721296 -6.34873438  0.9624905  -2.3778286 ]\n",
      " [-0.74686623 -4.46486044  0.50954503  1.25586879 -0.48812124 -0.48039484\n",
      "  -6.32025814  4.985394    0.9409622  -2.35221148]] [[ 0.70504558]\n",
      " [-5.55392265]\n",
      " [-1.70420146]\n",
      " [-2.1342082 ]\n",
      " [ 0.50336182]\n",
      " [ 0.87713188]\n",
      " [ 9.22067928]\n",
      " [ 9.26695538]\n",
      " [-2.28394055]\n",
      " [-2.02184415]]\n",
      "16000 0.00538544 [[-0.74606091 -4.59744644  1.20416415  0.6023528  -0.33780581 -0.75928861\n",
      "   5.10150671 -6.54030609  1.02001178 -2.44634104]\n",
      " [-0.7602762  -4.59742641  0.5316987   1.31584835 -0.51460242 -0.50168902\n",
      "  -6.51202679  5.16506815  0.99788475 -2.42254424]] [[ 0.75845444]\n",
      " [-5.8030653 ]\n",
      " [-1.83908188]\n",
      " [-2.28152776]\n",
      " [ 0.52788508]\n",
      " [ 0.91998827]\n",
      " [ 9.75413895]\n",
      " [ 9.80312729]\n",
      " [-2.44162655]\n",
      " [-2.11036754]]\n",
      "20000 0.0040668 [[-0.75580847 -4.69322824  1.24171555  0.63101751 -0.35436061 -0.78008652\n",
      "   5.23295641 -6.67398882  1.0652957  -2.49725723]\n",
      " [-0.77029651 -4.69320536  0.54869497  1.35993207 -0.53346246 -0.51614642\n",
      "  -6.64593792  5.29323149  1.04316568 -2.47466898]] [[  0.79610598]\n",
      " [ -5.99006748]\n",
      " [ -1.93990552]\n",
      " [ -2.39274669]\n",
      " [  0.54554516]\n",
      " [  0.95042938]\n",
      " [ 10.14355278]\n",
      " [ 10.1939621 ]\n",
      " [ -2.56228805]\n",
      " [ -2.17926168]]\n",
      "[array([[ 0.00241106],\n",
      "       [ 0.99605393],\n",
      "       [ 0.99605149],\n",
      "       [ 0.0059254 ]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 4000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0))\n",
    "\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.700846 [[ 0.39776748 -0.22293001  0.3412393  -0.57779938 -0.6393913 ]\n",
      " [ 0.69097     0.65415448 -0.28799036 -0.02191218 -0.89048553]] [[ 0.76226175 -0.06589856 -0.29528084  0.29179454]\n",
      " [-0.94714946  0.11760885  0.18141089 -0.95753485]\n",
      " [-0.92602921  0.67295933 -0.54780787 -0.05619263]\n",
      " [ 0.21244694 -0.16301087  0.63588417 -0.57583523]\n",
      " [-0.79140913  0.63127655  0.15852229  0.41589442]]\n",
      "4000 0.691782 [[ 0.45119584 -0.38180345  0.40844983 -0.63317966 -0.63092858]\n",
      " [ 0.68571591  0.84390891 -0.28297582  0.03112993 -0.93557441]] [[ 0.74379474 -0.14752619 -0.21970776  0.34231362]\n",
      " [-0.95118713  0.11790286  0.14838721 -1.12224054]\n",
      " [-0.93212599  0.67778522 -0.56667155 -0.04573681]\n",
      " [ 0.19510946 -0.21197037  0.62882167 -0.66049933]\n",
      " [-0.77089345  0.76783371 -0.03541021  0.16074578]]\n",
      "8000 0.141503 [[ 1.82208431 -2.80125093  2.66344547 -2.29024553 -3.15621352]\n",
      " [ 2.06240916  4.22189474 -1.09472704  0.70652229 -3.47796702]] [[ 1.68940616 -1.23733091  0.09898234  0.98444045]\n",
      " [-2.14720321  1.77073431 -0.38654143 -3.26462293]\n",
      " [-1.71287751  1.72498298 -1.03316009  0.17613879]\n",
      " [ 1.56309474 -1.81090343  1.07110703 -0.43006861]\n",
      " [-2.06323791  2.58458734 -0.84520477 -0.90960217]]\n",
      "12000 0.00650888 [[ 2.35456657 -3.77050257  3.81619143 -3.51579332 -3.88608217]\n",
      " [ 2.4655149   5.39447927 -1.81745636  1.33490527 -4.03729773]] [[ 2.34208965 -1.9910357   0.3747429   1.21901631]\n",
      " [-3.32466245  3.22614789 -0.74028486 -4.16033792]\n",
      " [-2.33125734  2.28216147 -1.42879081  0.09303266]\n",
      " [ 2.5250802  -2.82200432  1.5484941  -0.19601776]\n",
      " [-2.58041406  3.10588074 -1.1490761  -1.08418977]]\n",
      "16000 0.00292446 [[ 2.45432305 -3.9345355   4.0094099  -3.74808979 -4.00879192]\n",
      " [ 2.53672504  5.60117865 -1.95693707  1.4871887  -4.1269803 ]] [[ 2.47214174 -2.13870955  0.44164199  1.26656497]\n",
      " [-3.57594872  3.53502369 -0.82388806 -4.3119626 ]\n",
      " [-2.44259453  2.37929153 -1.52227199  0.0634703 ]\n",
      " [ 2.71816516 -3.02146173  1.66917384 -0.13336176]\n",
      " [-2.66411543  3.18742275 -1.21330798 -1.11176944]]\n",
      "20000 0.00184387 [[ 2.507864   -4.0208993   4.11137533 -3.873034   -4.07289314]\n",
      " [ 2.57495356  5.71101284 -2.03174019  1.57261479 -4.17383528]] [[ 2.54260278 -2.21809316  0.48006535  1.29394782]\n",
      " [-3.71511006  3.70431995 -0.87314111 -4.39123917]\n",
      " [-2.50212336  2.43223667 -1.5759238   0.04494801]\n",
      " [ 2.82402349 -3.13136959  1.73939931 -0.09502158]\n",
      " [-2.70713782  3.22894096 -1.24941123 -1.12640738]]\n",
      "[array([[ 0.00108809],\n",
      "       [ 0.99798512],\n",
      "       [ 0.99854624],\n",
      "       [ 0.00281112]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 4000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
