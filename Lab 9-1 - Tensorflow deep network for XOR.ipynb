{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR with logistic refression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.loadtxt.html\n",
    "xy = np.loadtxt('train_data/lab9-1_train.txt', unpack=True)\n",
    "x_data = np.transpose(xy[0:-1])\n",
    "y_data = np.reshape(xy[-1], (4,1))\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, len(x_data)], -1.0, 1.0))\n",
    "\n",
    "# Our hypothesis\n",
    "h = tf.matmul(W, X)\n",
    "hypothesis = tf.div(1., 1.+tf.exp(-h))\n",
    "# cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1.-hypothesis))\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.01) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Before starting, initialize the bariables. We will 'run' this first.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.787676 [[ 0.49950218  0.81834936  0.88301283  0.03217489]]\n",
      "200 0.715844 [[ 0.49950218  0.67293131  0.72450697 -0.27174893]]\n",
      "400 0.698321 [[ 0.49950218  0.60373616  0.64413273 -0.42131904]]\n",
      "600 0.694323 [[ 0.49950218  0.57254994  0.60404766 -0.4925912 ]]\n",
      "800 0.693421 [[ 0.49950218  0.55918252  0.58371681 -0.5262894 ]]\n",
      "[array([[ 0.5077365 ,  0.50295472]], dtype=float32), array([[ 1.,  1.]], dtype=float32), array([[False, False],\n",
      "       [ True,  True],\n",
      "       [ True,  True],\n",
      "       [False, False]], dtype=bool), 0.5]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # fit the line.\n",
    "    for step in range(1000):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis + 0.5), Y)\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(sess.run([hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], feed_dict={X:x_data, Y:y_data}))\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does not work!\n",
    "우리가 예상한 값은 [0,1,1,0]이지만 결과는 [1,1,0,0]이 나옴  \n",
    "50% 밖에 맞지 않음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_uniform([2,2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([2,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Our hypothesis\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize\n",
    "a = tf.Variable(0.1) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Before starting, initialize the bariables. We will 'run' this first.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.694639 [[ 0.35111278 -0.24913292]\n",
      " [-0.54445231  0.0047496 ]] [[ 0.02559432]\n",
      " [-0.26434758]]\n",
      "2000 0.69312 [[ 0.34123725 -0.239351  ]\n",
      " [-0.57211524 -0.02755926]] [[ 0.08923094]\n",
      " [-0.22271045]]\n",
      "4000 0.693052 [[ 0.34027499 -0.23147982]\n",
      " [-0.62409663 -0.06462664]] [[ 0.14929619]\n",
      " [-0.2245995 ]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # fit the line.\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W1), sess.run(W2))\n",
    "            \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.floor(hypothesis+0.5), Y)\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy],\n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print(\"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wide network: Use more neurons in each layer. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 4000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NN for XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0))\n",
    "\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 4000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
