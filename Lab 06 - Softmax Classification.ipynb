{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax function\n",
    "\n",
    "$$S(y_i) = \\frac {e^{y_j}} {\\sum_{j} e^{y_j}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('train_data/lab06_train.txt', unpack=True, dtype='float32')\n",
    "x_data = np.transpose(xy[0:3])\n",
    "y_data = np.transpose(xy[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\", [None, 3]) # x1, x2 and 1 (for bias)\n",
    "Y = tf.placeholder(\"float\", [None, 3]) # A, B, C => 3 classes\n",
    "# Set modle weights\n",
    "W = tf.Variable(tf.zeros([3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WX vs XW\n",
    "\n",
    "x가 한개가 아니라 여러개가 되고 x의 값이 여러개가 되기 때문에 그것을 조금 더 쉽게 처리하기 위한 하나의 트릭.  \n",
    "순서나 행과 열의 의미는 크지않다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "# First, we multiply x by W with the expression tf.matmul(x, W).\n",
    "# This is flipped from when we multiplied them in out equation,\n",
    "# where we had Wx, as a small trick to deal with x being\n",
    "# a 2D tensor with multiple inputs.\n",
    "# We then add b, and finally apply tf.nn.softmax.\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W)) # Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$D(S, L) = - \\sum_i L_i log(S_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Corss entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.09774 [[ -8.33333252e-05   4.16666626e-05   4.16666480e-05]\n",
      " [  1.66666694e-04   2.91666773e-04  -4.58333408e-04]\n",
      " [  1.66666636e-04   4.16666706e-04  -5.83333429e-04]]\n",
      "200 1.05962 [[-0.02051384 -0.00103983  0.02155367]\n",
      " [ 0.01406438  0.01097753 -0.02504191]\n",
      " [ 0.01431208  0.03574873 -0.05006079]]\n",
      "400 1.04985 [[-0.04282598 -0.00625899  0.04908497]\n",
      " [ 0.01747187  0.00156368 -0.01903554]\n",
      " [ 0.01831204  0.04954104 -0.06785304]]\n",
      "600 1.0407 [[-0.06517859 -0.01176361  0.07694222]\n",
      " [ 0.01943521 -0.00848972 -0.01094548]\n",
      " [ 0.0211558   0.06118308 -0.0823388 ]]\n",
      "800 1.03194 [[-0.08734013 -0.01729389  0.10463405]\n",
      " [ 0.0211172  -0.01796171 -0.00315548]\n",
      " [ 0.02396628  0.07198346 -0.09594974]]\n",
      "1000 1.02354 [[-0.10928574 -0.02282181  0.13210757]\n",
      " [ 0.02266254 -0.02678034  0.00411783]\n",
      " [ 0.02685853  0.08210357 -0.10896212]]\n",
      "1200 1.01547 [[-0.13101467 -0.02834092  0.15935561]\n",
      " [ 0.02409703 -0.03497621  0.01087923]\n",
      " [ 0.029832    0.091598   -0.12143001]]\n",
      "1400 1.0077 [[-0.15252906 -0.03384715  0.18637618]\n",
      " [ 0.02543302 -0.04258838  0.01715542]\n",
      " [ 0.03287466  0.10050805 -0.13338271]]\n",
      "1600 1.00021 [[-0.17383142 -0.03933692  0.21316831]\n",
      " [ 0.02668081 -0.04965464  0.0229739 ]\n",
      " [ 0.03597427  0.10887136 -0.14484565]]\n",
      "1800 0.992979 [[-0.19492456 -0.04480688  0.23973146]\n",
      " [ 0.02784993 -0.05621058  0.02836074]\n",
      " [ 0.03911954  0.11672314 -0.15584265]]\n",
      "2000 0.985988 [[-0.21581143 -0.05025396  0.26606542]\n",
      " [ 0.02894915 -0.06228962  0.03334056]\n",
      " [ 0.04230019  0.12409624 -0.16639642]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 200 == 0:\n",
    "        print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test & one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46272627  0.35483006  0.18244371]] [0]\n",
      "[[ 0.33820099  0.42101386  0.24078514]] [1]\n",
      "[[ 0.33820099  0.42101386  0.24078514]] [2]\n"
     ]
    }
   ],
   "source": [
    "a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7]]}) # bias, hours, attendance, A = [1, 0, 0]\n",
    "print (a, sess.run(tf.arg_max(a, 1)))\n",
    "\n",
    "b = sess.run(hypothesis, feed_dict={X:[[1, 3, 4]]})\n",
    "print (b, sess.run(tf.arg_max(b, 1)))\n",
    "\n",
    "c = sess.run(hypothesis, feed_dict={X:[[1, 1, 0]]})\n",
    "print (b, sess.run(tf.arg_max(c, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46272627  0.35483006  0.18244371]\n",
      " [ 0.33820099  0.42101386  0.24078514]\n",
      " [ 0.27002314  0.29085544  0.4391214 ]] [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "all = sess.run(hypothesis, feed_dict={X:[[1, 11, 7], [1, 3, 4], [1, 1, 0]]})\n",
    "print (all, sess.run(tf.arg_max(all, 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
