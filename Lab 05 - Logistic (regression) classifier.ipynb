{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(X) = \\frac {1}{1 + e^{-W^TX}}$$\n",
    "$$cost(W) = -\\frac {1}{m} \\sum y\\log(H(x)) + (1 - y)\\log(1 - H(x))$$\n",
    "$$W := W - \\alpha \\frac {\\delta} {\\delta W}cost(W)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('train_data/lab05_train.txt', unpack=True, dtype='float32')\n",
    "x_data = xy[0:-1]\n",
    "y_data = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1,len(x_data)], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(X) = \\frac {1}{1 + e^{-W^TX}}$\n",
    "\n",
    "tensorflow에는 sigmoid가 이미 구현이 되어있지만 직접 구현 해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our hypothesis\n",
    "h = tf.matmul(W, X)\n",
    "hypothesis = tf.div(1., 1. + tf.exp(-h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cost(W) = -\\frac {1}{m} \\sum y\\log(H(x)) + (1 - y)\\log(1 - H(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W := W - \\alpha \\frac {\\delta} {\\delta W}cost(W)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "a= tf.Variable(0.1) # Learning rate, alpha, step\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-fa983e1ecb88>:2 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "#Before starting, initialize the variables. We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.63048 [[ 0.48112115 -0.49216384 -0.40385735]]\n",
      "20 0.705746 [[ 0.2611894  -0.16314514  0.15722942]]\n",
      "40 0.653862 [[-0.04562403 -0.18099457  0.2538906 ]]\n",
      "60 0.610785 [[-0.33122361 -0.17710862  0.32221466]]\n",
      "80 0.57407 [[-0.59676743 -0.16405392  0.37552297]]\n",
      "100 0.542451 [[-0.8438412  -0.1476035   0.42033276]]\n",
      "120 0.515038 [[-1.07413483 -0.13043387  0.45995104]]\n",
      "140 0.491129 [[-1.28929412 -0.11375315  0.49611199]]\n",
      "160 0.470154 [[-1.49085116 -0.09806305  0.52976203]]\n",
      "180 0.451643 [[-1.68019724 -0.0835273   0.56144583]]\n",
      "200 0.435211 [[-1.85857677 -0.07015176  0.59149927]]\n",
      "220 0.420543 [[-2.02709341 -0.05787325  0.62014627]]\n",
      "240 0.407378 [[-2.18672109 -0.04660244  0.64754862]]\n",
      "260 0.395501 [[-2.3383193  -0.03624405  0.67383099]]\n",
      "280 0.384732 [[-2.4826436  -0.02670658  0.69909525]]\n",
      "300 0.374924 [[-2.62035966 -0.01790606  0.72342694]]\n",
      "320 0.365952 [[-2.75205612 -0.0097669   0.74690074]]\n",
      "340 0.35771 [[ -2.87825298e+00  -2.22186930e-03   7.69581735e-01]]\n",
      "360 0.350112 [[-2.99941182  0.0047881   0.79152834]]\n",
      "380 0.343081 [[-3.11594129  0.01131523  0.81279242]]\n",
      "400 0.336553 [[-3.22820854  0.01740566  0.83342135]]\n",
      "420 0.330473 [[-3.33653927  0.02309978  0.85345745]]\n",
      "440 0.324793 [[-3.44122672  0.02843367  0.87293935]]\n",
      "460 0.319473 [[-3.54253364  0.03343885  0.89190221]]\n",
      "480 0.314477 [[-3.64069724  0.03814376  0.91037798]]\n",
      "500 0.309773 [[-3.73593187  0.04257341  0.92839617]]\n",
      "520 0.305334 [[-3.8284328   0.04675031  0.94598353]]\n",
      "540 0.301136 [[-3.91837597  0.05069448  0.96316504]]\n",
      "560 0.297159 [[-4.00592184  0.054424    0.9799633 ]]\n",
      "580 0.293382 [[-4.09121752  0.05795494  0.99639922]]\n",
      "600 0.289789 [[-4.17439651  0.0613021   1.01249206]]\n",
      "620 0.286367 [[-4.2555809   0.0644785   1.02825987]]\n",
      "640 0.283099 [[-4.3348856   0.06749643  1.04371917]]\n",
      "660 0.279977 [[-4.41241407  0.07036655  1.05888546]]\n",
      "680 0.276987 [[-4.48826075  0.07309879  1.07377291]]\n",
      "700 0.274121 [[-4.56251621  0.07570229  1.08839512]]\n",
      "720 0.27137 [[-4.63526106  0.07818539  1.10276413]]\n",
      "740 0.268727 [[-4.7065711   0.08055542  1.11689186]]\n",
      "760 0.266182 [[-4.77651882  0.08281974  1.13078892]]\n",
      "780 0.263731 [[-4.84516668  0.08498435  1.14446509]]\n",
      "800 0.261367 [[-4.91257715  0.0870553   1.15793049]]\n",
      "820 0.259085 [[-4.97880697  0.08903807  1.17119348]]\n",
      "840 0.25688 [[-5.04390955  0.0909376   1.18426287]]\n",
      "860 0.254746 [[-5.10793543  0.09275874  1.19714618]]\n",
      "880 0.25268 [[-5.17093086  0.09450557  1.20985103]]\n",
      "900 0.250679 [[-5.23293781  0.09618218  1.2223841 ]]\n",
      "920 0.248737 [[-5.29400015  0.09779251  1.2347523 ]]\n",
      "940 0.246853 [[-5.35415506  0.09933972  1.24696159]]\n",
      "960 0.245023 [[-5.4134388   0.10082719  1.25901794]]\n",
      "980 0.243243 [[-5.47188568  0.10225794  1.27092695]]\n",
      "1000 0.241512 [[-5.52952766  0.10363465  1.28269386]]\n",
      "1020 0.239827 [[-5.58639526  0.1049601   1.29432344]]\n",
      "1040 0.238186 [[-5.64251852  0.10623687  1.30582047]]\n",
      "1060 0.236586 [[-5.69792318  0.10746712  1.31718957]]\n",
      "1080 0.235026 [[-5.752635    0.10865299  1.32843482]]\n",
      "1100 0.233504 [[-5.80667877  0.10979658  1.33956051]]\n",
      "1120 0.232017 [[-5.86007833  0.11089986  1.35057032]]\n",
      "1140 0.230565 [[-5.91285515  0.11196461  1.36146784]]\n",
      "1160 0.229145 [[-5.96503019  0.11299253  1.37225676]]\n",
      "1180 0.227757 [[-6.01661921  0.11398504  1.38293982]]\n",
      "1200 0.226399 [[-6.06764841  0.1149441   1.39352095]]\n",
      "1220 0.22507 [[-6.11813164  0.11587087  1.40400279]]\n",
      "1240 0.223768 [[-6.16808605  0.11676671  1.4143883 ]]\n",
      "1260 0.222493 [[-6.21752882  0.11763276  1.42468047]]\n",
      "1280 0.221243 [[-6.26647472  0.11847045  1.43488157]]\n",
      "1300 0.220017 [[-6.31494045  0.11928097  1.44499445]]\n",
      "1320 0.218815 [[-6.36293745  0.12006536  1.45502114]]\n",
      "1340 0.217636 [[-6.4104805   0.12082446  1.46496415]]\n",
      "1360 0.216478 [[-6.45758247  0.1215596   1.47482562]]\n",
      "1380 0.215341 [[-6.50425625  0.12227142  1.48460782]]\n",
      "1400 0.214224 [[-6.55051327  0.12296104  1.49431276]]\n",
      "1420 0.213126 [[-6.59636497  0.1236291   1.50394249]]\n",
      "1440 0.212047 [[-6.64182138  0.12427634  1.51349878]]\n",
      "1460 0.210987 [[-6.68689203  0.12490362  1.52298295]]\n",
      "1480 0.209943 [[-6.73159266  0.12551206  1.53239775]]\n",
      "1500 0.208917 [[-6.77592802  0.12610203  1.54174423]]\n",
      "1520 0.207907 [[-6.81990814  0.12667415  1.5510242 ]]\n",
      "1540 0.206912 [[-6.8635416   0.12722908  1.56023896]]\n",
      "1560 0.205933 [[-6.90683842  0.12776747  1.56939042]]\n",
      "1580 0.204969 [[-6.94980478  0.12828979  1.57847953]]\n",
      "1600 0.204019 [[-6.99245024  0.12879667  1.58750808]]\n",
      "1620 0.203083 [[-7.03478146  0.12928873  1.59647715]]\n",
      "1640 0.20216 [[-7.07680655  0.12976651  1.60538805]]\n",
      "1660 0.20125 [[-7.11853218  0.13023037  1.61424232]]\n",
      "1680 0.200353 [[-7.15996456  0.13068075  1.62304068]]\n",
      "1700 0.199469 [[-7.20111084  0.13111819  1.63178468]]\n",
      "1720 0.198596 [[-7.24197769  0.13154298  1.64047539]]\n",
      "1740 0.197735 [[-7.28257084  0.13195565  1.64911366]]\n",
      "1760 0.196885 [[-7.322896    0.13235651  1.65770078]]\n",
      "1780 0.196046 [[-7.36295938  0.13274619  1.66623771]]\n",
      "1800 0.195218 [[-7.40276575  0.13312469  1.67472517]]\n",
      "1820 0.1944 [[-7.4423213   0.1334928   1.68316448]]\n",
      "1840 0.193592 [[-7.48163033  0.13385041  1.69155633]]\n",
      "1860 0.192794 [[-7.52069807  0.13419773  1.69990194]]\n",
      "1880 0.192006 [[-7.55953026  0.13453564  1.70820189]]\n",
      "1900 0.191227 [[-7.5981307   0.13486415  1.71645701]]\n",
      "1920 0.190457 [[-7.63650417  0.13518359  1.72466803]]\n",
      "1940 0.189696 [[-7.67465448  0.13549422  1.73283601]]\n",
      "1960 0.188944 [[-7.7125864   0.13579644  1.74096143]]\n",
      "1980 0.1882 [[-7.75030327  0.13609017  1.74904513]]\n",
      "2000 0.187464 [[-7.78780985  0.13637589  1.75708783]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "    if step %  20 == 0:\n",
    "        print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask to ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n",
      "[[ True]]\n"
     ]
    }
   ],
   "source": [
    "# study hour attendance\n",
    "print (sess.run(hypothesis, feed_dict={X:[[1],[2],[3]]}) > 0.5) # 0.5보다 큰가?\n",
    "print (sess.run(hypothesis, feed_dict={X:[[1],[5],[5]]}) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True]]\n"
     ]
    }
   ],
   "source": [
    "print (sess.run(hypothesis, feed_dict={X:[[1,1],[4,3],[3,5]]}) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Youtube Q&A**\n",
    "> 보통 0과 1로 레이블을 구분하니 0.5를 많이 사용하는데 본인의 문제와 학습 데이타에 따라 다른값을 줄수도 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
