{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('train_data/lab06_train.txt', unpack=True, dtype='float32')\n",
    "x_data = np.transpose(xy[0:3])\n",
    "y_data = np.transpose(xy[3:])\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\", [None, 3]) # x1, x2 and 1 (for bias)\n",
    "Y = tf.placeholder(\"float\", [None, 3]) # A, B, C => 3 classes\n",
    "\n",
    "# Set modle weights\n",
    "W = tf.Variable(tf.zeros([3, 3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W)) # Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate를 큰 값으로 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "learning_rate = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan [[-0.83333319  0.4166666   0.41666645]\n",
      " [ 1.66666687  2.91666746 -4.58333397]\n",
      " [ 1.66666627  4.16666698 -5.83333397]]\n",
      "200 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "400 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "600 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "800 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "1000 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "1200 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "1400 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "1600 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "1800 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n",
      "2000 nan [[ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]]\n"
     ]
    }
   ],
   "source": [
    "# Corss entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1))\n",
    "\n",
    "#Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 200 == 0:\n",
    "        print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate이 너무 커서 overshooting이 되어서 학습이 전혀 일어나지 않않다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate를 작은 값으로 주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.09852 [[ -8.33333161e-06   4.16666580e-06   4.16666444e-06]\n",
      " [  1.66666687e-05   2.91666747e-05  -4.58333379e-05]\n",
      " [  1.66666614e-05   4.16666662e-05  -5.83333349e-05]]\n",
      "200 1.08514 [[-0.00175495  0.00064726  0.00110769]\n",
      " [ 0.00293629  0.00489164 -0.00782793]\n",
      " [ 0.00294097  0.00740635 -0.01034732]]\n",
      "400 1.07722 [[-0.0036236   0.00098153  0.00264207]\n",
      " [ 0.00522766  0.00818141 -0.01340907]\n",
      " [ 0.00524379  0.01319837 -0.01844216]]\n",
      "600 1.07226 [[-0.00557707  0.00108985  0.00448722]\n",
      " [ 0.00708463  0.01032533 -0.01740997]\n",
      " [ 0.0071169   0.01783946 -0.02495635]]\n",
      "800 1.06895 [[-0.00759301  0.00103238  0.00656063]\n",
      " [ 0.00862161  0.01163302 -0.02025463]\n",
      " [ 0.00867387  0.02163565 -0.03030949]]\n",
      "1000 1.06658 [[-0.00965698  0.00085276  0.00880422]\n",
      " [ 0.00991114  0.01232841 -0.02223956]\n",
      " [ 0.00998697  0.02480848 -0.03479542]]\n",
      "1200 1.06475 [[-0.01175893  0.00058266  0.01117626]\n",
      " [ 0.01100301  0.01257371 -0.02357675]\n",
      " [ 0.01110593  0.02751854 -0.03862444]]\n",
      "1400 1.06325 [[-0.01389133  0.00024516  0.01364617]\n",
      " [ 0.01193393  0.0124868  -0.02442075]\n",
      " [ 0.01206745  0.0298826  -0.04195001]]\n",
      "1600 1.06195 [[-0.01604833 -0.00014285  0.01619117]\n",
      " [ 0.01273244  0.01215373 -0.02488619]\n",
      " [ 0.01290009  0.031986   -0.04488603]]\n",
      "1800 1.06077 [[-0.01822517 -0.00056892  0.01879408]\n",
      " [ 0.01342153  0.01163764 -0.02505921]\n",
      " [ 0.01362685  0.0338914  -0.04751818]]\n",
      "2000 1.05967 [[-0.02041796 -0.00102386  0.02144181]\n",
      " [ 0.01402011  0.01098517 -0.02500531]\n",
      " [ 0.01426658  0.03564513 -0.04991166]]\n"
     ]
    }
   ],
   "source": [
    "# Corss entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1))\n",
    "\n",
    "#Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 200 == 0:\n",
    "        print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate를 너무 작은 값으로 주어서 학습이 거의 일어나지 않았다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0678 [[-0.00833333  0.00416667  0.00416666]\n",
      " [ 0.01666667  0.02916667 -0.04583334]\n",
      " [ 0.01666666  0.04166667 -0.05833334]]\n",
      "200 0.699681 [[-1.5737735  -0.36410642  1.93788099]\n",
      " [ 0.0967759  -0.09235884 -0.00441682]\n",
      " [ 0.24915566  0.23823613 -0.48739177]]\n",
      "400 0.594579 [[-2.54309034 -0.43173078  2.97482228]\n",
      " [ 0.13064831 -0.04841127 -0.08223619]\n",
      " [ 0.40734777  0.22857714 -0.63592446]]\n",
      "600 0.535829 [[-3.31521416 -0.39115471  3.70637012]\n",
      " [ 0.13982886 -0.02464214 -0.11518568]\n",
      " [ 0.54843497  0.21297167 -0.76140594]]\n",
      "800 0.494312 [[-3.98393679 -0.31143472  4.29537106]\n",
      " [ 0.1417881  -0.00935038 -0.13243635]\n",
      " [ 0.6748786   0.1950776  -0.86995488]]\n",
      "1000 0.461916 [[ -4.58334923e+00  -2.18527570e-01   4.80187750e+00]\n",
      " [  1.41456679e-01   1.54198625e-03  -1.42996773e-01]\n",
      " [  7.89354861e-01   1.77009344e-01  -9.66362596e-01]]\n",
      "1200 0.435343 [[-5.13021469 -0.12343737  5.25365353]\n",
      " [ 0.14044461  0.00979479 -0.15023731]\n",
      " [ 0.89399701  0.15975396 -1.05374885]]\n",
      "1400 0.412891 [[-5.63466215 -0.03106253  5.66572714]\n",
      " [ 0.1393245   0.01630212 -0.15562418]\n",
      " [ 0.99044132  0.14372151 -1.13416028]]\n",
      "1600 0.393535 [[-6.10366583  0.05645988  6.04720736]\n",
      " [ 0.13829574  0.02157287 -0.15986556]\n",
      " [ 1.07996321  0.12904176 -1.20900333]]\n",
      "1800 0.376595 [[-6.54242659  0.13831529  6.40411282]\n",
      " [ 0.13741526  0.02592302 -0.16333508]\n",
      " [ 1.16357517  0.11571171 -1.27928567]]\n",
      "2000 0.361591 [[-6.95501471  0.21433842  6.7406764 ]\n",
      " [ 0.13668649  0.02956286 -0.16624542]\n",
      " [ 1.2420913   0.1036661  -1.3457557 ]]\n"
     ]
    }
   ],
   "source": [
    "# Corss entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), reduction_indices=1))\n",
    "\n",
    "#Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 200 == 0:\n",
    "        print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어느정도 학습이 되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data and set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist.input_data import read_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "x = tf.placeholder(\"float\", [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(\"float\", [None, 10]) # 0-9 digits recognition => 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activiation (hypothesis) and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct model\n",
    "activation = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(activation), reduction_indices=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) # Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training batch\n",
    "\n",
    "training data set이 많기 때문에 잘라서 학습 시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train_data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting train_data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting train_data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting train_data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "laerning_rate = 0.01\n",
    "training_epochs = 5\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mnist = read_data_sets(\"train_data/MNIST_data/\", one_hot=True)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.521184075\n",
      "Epoch: 0002 cost= 0.352583863\n",
      "Epoch: 0003 cost= 0.323971806\n",
      "Epoch: 0004 cost= 0.309509690\n",
      "Epoch: 0005 cost= 0.299753569\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Training cycle\n",
    "for epoch in range(training_epochs) :\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch) :\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        # Compute average loss\n",
    "        avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys})/total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    \n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict & Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [4]\n",
      "Predication:  [4]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "from random import randint\n",
    "\n",
    "r = randint(0, mnist.test.num_examples - 1)\n",
    "print (\"Label: \", sess.run(tf.argmax(activation, 1), {x: mnist.test.images[r:r+1]}))\n",
    "print (\"Predication: \", sess.run(tf.argmax(activation, 1), {x: mnist.test.images[r:r+1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLEmJDGFJSvT/KS7h4dVW2FoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f16428daa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the img\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "test data set을 다 돌려서 정확도가 얼마인지 본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9187\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(activation, 1), tf.argmax(y, 1))\n",
    "# Calcuate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print (\"Accuracy: \", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}, session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy.eval이 sess.run과 같은 역할을 함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
