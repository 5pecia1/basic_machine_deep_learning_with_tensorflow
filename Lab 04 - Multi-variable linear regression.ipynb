{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(x_1, x_2) = w_1x_1 + w_2x_2 + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1_data = [1,0,3,0,5]\n",
    "x2_data = [0,2,0,4,0]\n",
    "y_data = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to find values for W and b that compute y_dta = W * x_data + b\n",
    "# (We know that W should be 1 and b 0, bu Tensorflow will\n",
    "# figure that out for us.)\n",
    "W1 = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our hypothesis\n",
    "hypothesis = W1 * x1_data + W2 * x2_data + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simplified cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Minimize\n",
    "a = tf.Variable(0.1) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Before starting, initalize the varibles. We will 'run' this first\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Lanch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.618234 [ 1.09379697] [ 0.78967094] [ 0.70539463]\n",
      "20 0.0210947 [ 0.90949064] [ 0.89261091] [ 0.34431133]\n",
      "40 0.00610777 [ 0.95129752] [ 0.94221491] [ 0.18527068]\n",
      "60 0.00176845 [ 0.97379369] [ 0.9689064] [ 0.09969243]\n",
      "80 0.000512038 [ 0.98589867] [ 0.98326886] [ 0.05364354]\n",
      "100 0.000148257 [ 0.99241215] [ 0.99099714] [ 0.02886511]\n",
      "120 4.29272e-05 [ 0.99591714] [ 0.99515563] [ 0.01553207]\n",
      "140 1.24296e-05 [ 0.99780297] [ 0.99739325] [ 0.00835765]\n",
      "160 3.59869e-06 [ 0.9988178] [ 0.99859732] [ 0.00449717]\n",
      "180 1.042e-06 [ 0.99936384] [ 0.99924523] [ 0.0024199]\n",
      "200 3.01633e-07 [ 0.99965769] [ 0.99959391] [ 0.00130211]\n",
      "220 8.73847e-08 [ 0.99981576] [ 0.99978149] [ 0.00070063]\n",
      "240 2.5295e-08 [ 0.99990082] [ 0.9998824] [ 0.00037702]\n",
      "260 7.32455e-09 [ 0.99994665] [ 0.9999367] [ 0.00020287]\n",
      "280 2.11872e-09 [ 0.99997139] [ 0.99996597] [ 0.00010918]\n",
      "300 6.13613e-10 [ 0.99998462] [ 0.9999817] [  5.87548820e-05]\n",
      "320 1.78855e-10 [ 0.99999177] [ 0.99999011] [  3.16562146e-05]\n",
      "340 5.14888e-11 [ 0.99999547] [ 0.9999947] [  1.69791674e-05]\n",
      "360 1.47566e-11 [ 0.99999762] [ 0.9999972] [  9.11612278e-06]\n",
      "380 4.58158e-12 [ 0.99999869] [ 0.99999845] [  4.89134527e-06]\n",
      "400 1.29887e-12 [ 0.99999934] [ 0.99999923] [  2.65021094e-06]\n",
      "420 2.95586e-13 [ 0.99999958] [ 0.99999958] [  1.41043438e-06]\n",
      "440 1.93268e-13 [ 0.99999982] [ 0.99999976] [  8.38229937e-07]\n",
      "460 4.83169e-14 [ 0.99999988] [ 0.99999982] [  4.90138916e-07]\n",
      "480 2.55795e-14 [ 0.99999988] [ 0.99999994] [  2.70793862e-07]\n",
      "500 2.27374e-14 [ 1.] [ 0.99999994] [  2.13573472e-07]\n",
      "520 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "540 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "560 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "580 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "600 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "620 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "640 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "660 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "680 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "700 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "720 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "740 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "760 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "780 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "800 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "820 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "840 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "860 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "880 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "900 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "920 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "940 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "960 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "980 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1000 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1020 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1040 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1060 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1080 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1100 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1120 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1140 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1160 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1180 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1200 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1220 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1240 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1260 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1280 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1300 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1320 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1340 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1360 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1380 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1400 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1420 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1440 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1460 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1480 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1500 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1520 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1540 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1560 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1580 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1600 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1620 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1640 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1660 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1680 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1700 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1720 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1740 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1760 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1780 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1800 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1820 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1840 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1860 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1880 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1900 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1920 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1940 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1960 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "1980 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n",
      "2000 1.42109e-14 [ 1.] [ 0.99999994] [  1.75426536e-07]\n"
     ]
    }
   ],
   "source": [
    "# Fit the line.\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 ==0:\n",
    "        print(step, sess.run(cost), sess.run(W1), sess.run(W2), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix\n",
    "\n",
    "$$w_1x_1 + w_2x_2 + w_3x_3 + ... + w_nx_n$$\n",
    "$$[\\begin{matrix} w_1 & x_2 & w_3 \\end{matrix}] \\times [\\begin{matrix}x_1 \\\\x_2 \\\\x_3 \\end{matrix}] = [\\begin{matrix} w_1 \\times x_1 + w_2 \\times x_2 + w_3 \\times x_3 \\end{matrix}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[0., 2., 0., 4., 0.],\n",
    "         [1., 0., 3., 0., 5.]]\n",
    "y_data = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차원이 있는 W를 만들어 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try to find values for W\n",
    "W = tf.Variable(tf.random_uniform([1,2], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix 곱하기를 해야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our hypothesis\n",
    "hypothesis = tf.matmul(W, x_data) + b\n",
    "\n",
    "# Simplified cost funcion\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "a = tf.Variable(0.1) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Before starting, initialize the variables. We will 'run this first.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.95732 [[ 0.89750087  1.4916476 ]] [ 0.13462275]\n",
      "20 5.28343e-05 [[ 0.99462563  0.99547088]] [ 0.01723166]\n",
      "40 1.52979e-05 [[ 0.9971081   0.99756265]] [ 0.00927208]\n",
      "60 4.42941e-06 [[ 0.9984439   0.99868852]] [ 0.00498924]\n",
      "80 1.28251e-06 [[ 0.99916267  0.99929428]] [ 0.00268468]\n",
      "100 3.71331e-07 [[ 0.99954939  0.99962026]] [ 0.00144459]\n",
      "120 1.07506e-07 [[ 0.99975753  0.99979562]] [ 0.0007773]\n",
      "140 3.11306e-08 [[ 0.99986953  0.99989003]] [ 0.00041825]\n",
      "160 9.01324e-09 [[ 0.99992979  0.99994087]] [ 0.00022506]\n",
      "180 2.61048e-09 [[ 0.99996227  0.99996817]] [ 0.00012107]\n",
      "200 7.53505e-10 [[ 0.99997967  0.99998283]] [  6.51333467e-05]\n",
      "220 2.21212e-10 [[ 0.99998903  0.9999907 ]] [  3.50449227e-05]\n",
      "240 6.24823e-11 [[ 0.9999941   0.99999499]] [  1.88896738e-05]\n",
      "260 1.8693e-11 [[ 0.99999684  0.99999738]] [  1.01921623e-05]\n",
      "280 5.30918e-12 [[ 0.99999827  0.99999857]] [  5.48578009e-06]\n",
      "300 1.67404e-12 [[ 0.99999905  0.99999928]] [  2.96808048e-06]\n",
      "320 5.59908e-13 [[ 0.99999952  0.9999997 ]] [  1.64247319e-06]\n",
      "340 1.0516e-13 [[ 0.9999997   0.99999976]] [  8.93839172e-07]\n",
      "360 6.82121e-14 [[ 0.99999982  0.99999988]] [  5.60053138e-07]\n",
      "380 2.55795e-14 [[ 0.99999994  0.99999988]] [  2.93024414e-07]\n",
      "400 4.83169e-14 [[ 0.99999994  0.99999994]] [  2.07193807e-07]\n",
      "420 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "440 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "460 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "480 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "500 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "520 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "540 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "560 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "580 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "600 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "620 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "640 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "660 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "680 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "700 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "720 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "740 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "760 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "780 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "800 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "820 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "840 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "860 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "880 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "900 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "920 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "940 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "960 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "980 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1000 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1020 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1040 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1060 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1080 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1100 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1120 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1140 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1160 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1180 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1200 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1220 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1240 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1260 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1280 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1300 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1320 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1340 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1360 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1380 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1400 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1420 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1440 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1460 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1480 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1500 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1520 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1540 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1560 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1580 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1600 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1620 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1640 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1660 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1680 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1700 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1720 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1740 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1760 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1780 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1800 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1820 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1840 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1860 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1880 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1900 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1920 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1940 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1960 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "1980 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n",
      "2000 4.83169e-14 [[ 0.99999994  0.99999994]] [  1.64278504e-07]\n"
     ]
    }
   ],
   "source": [
    "# Fit the line.\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "$$[\\begin{matrix} b & w_1 & x_2 & w_3 \\end{matrix}] \\times [\\begin{matrix} 1 \\\\x_1 \\\\x_2 \\\\x_3 \\end{matrix}] = [\\begin{matrix}b \\times 1 + w_1 \\times x_1 + w_2 \\times x_2 + w_3 \\times x_3 \\end{matrix}]$$\n",
    "$$H(X) = WX$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [[1, 1, 1, 1, 1],\n",
    "         [0., 2., 0., 4., 0.],\n",
    "         [1., 0., 3., 0., 5.]]\n",
    "y_data = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1,3],-1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our hypthesis\n",
    "# previous hypothesis with b, hypothesis = tf.matmul(W, x_data) + b\n",
    "hypothesis = tf.matmul(W, x_data)\n",
    "# Simplified cost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "a = tf.Variable(0.1) # Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Before starting, initialize the variables. We will 'run this first.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step, cost, b, W1, W2 순으로 출력된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "20 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "40 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "60 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "80 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "100 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "120 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "140 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "160 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "180 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "200 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "220 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "240 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "260 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "280 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "300 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "320 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "340 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "360 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "380 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "400 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "420 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "440 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "460 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "480 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "500 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "520 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "540 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "560 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "580 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "600 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "620 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "640 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "660 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "680 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "700 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "720 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "740 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "760 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "780 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "800 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "820 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "840 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "860 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "880 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "900 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "920 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "940 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "960 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "980 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1000 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1020 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1040 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1060 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1080 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1100 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1120 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1140 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1160 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1180 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1200 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1220 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1240 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1260 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1280 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1300 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1320 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1340 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1360 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1380 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1400 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1420 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1440 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1460 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1480 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1500 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1520 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1540 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1560 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1580 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1600 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1620 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1640 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1660 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1680 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1700 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1720 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1740 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1760 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1780 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1800 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1820 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1840 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1860 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1880 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1900 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1920 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1940 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1960 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "1980 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n",
      "2000 1.42109e-14 [[  1.76819995e-07   9.99999940e-01   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the line.\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data form file\n",
    "useing lab04_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.loadtxt.html\n",
    "xy = np.loadtxt('train_data/lab04_train.txt', unpack=True, dtype='float32')\n",
    "\n",
    "x_data = xy[0: -1]\n",
    "y_data = xy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [[ 1.  1.  1.  1.  1.]\n",
      " [ 1.  0.  3.  0.  5.]\n",
      " [ 0.  2.  0.  4.  0.]]\n",
      "y [ 1.  2.  3.  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "print ('x', x_data)\n",
    "print ('y', y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to find values for W\n",
    "W = tf.Variable(tf.random_uniform([1, len(x_data)], -5.0, 5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our hypothesis\n",
    "hypothesis = tf.matmul(W, x_data)\n",
    "\n",
    "# Simplified cost funcion\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize\n",
    "a = tf.Variable(0.1) # LEarning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Before starting, initialize the variables. We will 'run this first.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.06057e-14 [[ -3.00367560e-07   1.00000012e+00   1.00000012e+00]]\n",
      "2000 2.06057e-14 [[ -3.00367560e-07   1.00000012e+00   1.00000012e+00]]\n",
      "4000 2.06057e-14 [[ -3.00367560e-07   1.00000012e+00   1.00000012e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the line.\n",
    "for step in range(200001):\n",
    "    sess.run(train)\n",
    "    if step % 2000 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
